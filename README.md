
# Smart Research Assistant

## ðŸ“š Project Overview

The Smart Research Assistant is an AI-powered tool designed to enhance user interaction with documents such as research papers, legal files, technical manuals, or structured reports. This assistant allows users to upload documents, get concise summaries, ask free-form questions based on the content, and challenge their comprehension with logic-based questions generated by the system. All interactions are grounded in the document's content, ensuring accuracy and providing direct references.

This project aims to streamline the research and document review process by leveraging Natural Language Processing (NLP) and Large Language Models (LLMs) to provide intelligent assistance.

## âœ¨ Features

* **Document Upload:** Supports uploading documents in PDF and TXT formats.
* **Automatic Summarization:** Generates a concise summary (â‰¤ 150 words) of the uploaded document, providing a quick overview of its main ideas.
* **"Ask Anything" Mode:**
    * Allows users to ask any free-form question about the document's content.
    * Answers are contextually grounded in the document, preventing hallucination.
    * Each answer is supported by a confidence score and a direct reference/justification from the document.
* **"Challenge Me" Mode:**
    * Automatically generates three logic-based or comprehension-focused questions based on the document.
    * Users can attempt to answer these questions.
    * The assistant evaluates user answers, provides feedback, and refers to the document to justify its evaluation.
* **User-Friendly Interface:** Built with Streamlit for an intuitive and responsive web interface.

## ðŸš€ Getting Started

Follow these steps to set up and run the Smart Research Assistant on your local machine.

### Prerequisites

* Python 3.7+ installed.
* `pip` (Python package installer).

### 1. Clone the Repository

If you haven't already, clone this repository to your local machine:

```bash
git clone https://github.com/Abhiramreddymurthy/smart_research_assistant.git
cd smart_research_assistant
````

### 2\. Create a Virtual Environment

It's highly recommended to use a virtual environment to manage project dependencies and avoid conflicts with other Python projects.

```bash
python -m venv assistant_env
```

### 3\. Activate the Virtual Environment

  * **For Windows:**
    ```bash
    assistant_env\Scripts\activate
    ```
  * **For macOS/Linux:**
    ```bash
    source assistant_env/bin/activate
    ```
    (You'll see `(assistant_env)` prefix in your terminal once activated.)

### 4\. Install Required Libraries

Ensure you have a `requirements.txt` file in the root of your project with the following content:

```
streamlit==1.36.0
transformers==4.42.1
torch==2.3.1
pdfminer.six==20221105
nltk==3.8.1
pandas==2.2.2
```

Then, install the dependencies using pip:

```bash
pip install -r requirements.txt
```

### 5\. Run the Application

Once all dependencies are installed and your virtual environment is active, you can run the Streamlit application. Make sure your main application code is saved as `app.py` in the root of your project directory.

```bash
python -m streamlit run app.py
```

This command will open the Smart Research Assistant in your default web browser (usually at `http://localhost:8501`). Keep the terminal window open as long as the application is running.

## ðŸ“‚ Project Structure

```
smart_assistant_project/
â”œâ”€â”€ app.py                     # Main Streamlit application file
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project documentation (this file)

```

## ðŸ§  How It Works (Technical Overview)

  * **Frontend:** The user interface is built using `Streamlit`, a powerful Python library for creating web applications.
  * **Document Processing:** `pdfminer.six` is used to extract text content from uploaded PDF files, while TXT files are read directly.
  * **NLP Models (`Hugging Face Transformers`):**
      * **Summarization:** A pre-trained `BART` model (`sshleifer/distilbart-cnn-12-6`) generates document summaries.
      * **Question Answering:** A `DistilBERT` model (`distilbert/distilbert-base-uncased-distilled-squad`) is used to answer free-form questions by identifying answer spans within the document context.
      * **Question Generation:** A `GPT-2` model is used to generate comprehension-focused questions. *(Note: For more sophisticated logic-based questions, larger LLMs or fine-tuned models would yield better results.)*
  * **Answer Evaluation:** A basic string-matching and context-comparison logic is implemented, leveraging the QA model to derive a 'correct' answer for comparison. For production, more advanced semantic similarity methods would be ideal.
  * **Caching:** `@st.cache_resource` is used to efficiently load and reuse large AI models, preventing reloads on every user interaction.
  * **Session Management:** `st.session_state` is utilized to persist document text, generated questions, and user answers across Streamlit reruns.

## ðŸ›‘ Stopping the Application

To stop the Streamlit application, go to the terminal where it's running and press `Ctrl + C`.

To deactivate your virtual environment when you're done, type `deactivate` in the terminal.

## ðŸš§ Future Enhancements

  * **Robust Answer Evaluation:** Implement more sophisticated evaluation metrics (e.g., semantic similarity using Sentence-BERT, keyword extraction, fact comparison) for "Challenge Me" mode.
  * **Large Document Handling (RAG):** Integrate a Retrieval-Augmented Generation (RAG) system using vector databases (e.g., FAISS, ChromaDB) and text embedding models to efficiently handle and retrieve information from very large documents, overcoming LLM token limits.
  * **Improved Question Generation:** Utilize more advanced or fine-tuned LLMs (e.g., T5, FLAN-T5, or even commercial APIs like GPT-3.5/4 if feasible) for generating higher-quality, more challenging, and truly logic-based questions.
  * **User Authentication/History:** Add features for user accounts and saving interaction history.
  * **More File Types:** Support additional document formats (e.g., DOCX, EPUB).
  * **Deployment:** Deploy the application to a cloud platform (e.g., Heroku, AWS, Google Cloud) for public access.
  * **UI/UX Refinements:** Enhance the user interface with better loading indicators, clear error messages, and more visually appealing layouts.

<!-- end list -->

```
```
